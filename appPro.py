import os
import json
import faiss
import numpy as np
import streamlit as st
from sentence_transformers import SentenceTransformer
import openai
from dotenv import load_dotenv

# =====================
# ðŸ” API Key è®¾ç½®
# =====================
load_dotenv()
client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))  # æˆ–ç›´æŽ¥å¡«å†™ key

# =====================
# ðŸ“¦ åŠ è½½å‘é‡ç´¢å¼•å’Œå…ƒæ•°æ®
# =====================
data_dir = os.path.dirname(__file__)
index = faiss.read_index(os.path.join(data_dir, "faiss_index.index"))

with open(os.path.join(data_dir, "faiss_metadata.json"), "r", encoding="utf-8") as f:
    metadata = json.load(f)

# =====================
# ðŸ” åµŒå…¥æ¨¡åž‹
# =====================
embedder = SentenceTransformer("all-MiniLM-L6-v2")

# =====================
# ðŸŒ é¡µé¢ç•Œé¢
# =====================
st.set_page_config(page_title="è¯å­¦AIè¯¾å ‚ï½œæ™ºèƒ½é—®ç­”å®žéªŒå®¤", layout="wide")
st.title("ðŸ’Š è¯å­¦AIè¯¾å ‚ï½œæ™ºèƒ½é—®ç­”å®žéªŒå®¤")
st.markdown("è¯·åœ¨ä¸‹æ–¹è¾“å…¥ä½ çš„é—®é¢˜ï¼Œç³»ç»Ÿå°†ä»Žè¯å“æ–‡çŒ®ä¸­æå–ç­”æ¡ˆå¹¶å¼•ç”¨å‡ºå¤„ã€‚")

query = st.text_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼š", "é˜¿å¸åŒ¹æž—å’Œå¸ƒæ´›èŠ¬å“ªä¸ªå¯¹èƒƒåˆºæ¿€æ›´å°ï¼Ÿ")
submit = st.button("æäº¤é—®é¢˜")

# =====================
# ðŸ”„ æ£€ç´¢ + ç”Ÿæˆå‡½æ•°
# =====================
def search_faiss(question, top_k=5):
    vec = embedder.encode([question], convert_to_numpy=True).astype("float32")
    D, I = index.search(vec, top_k)
    return [metadata[i] for i in I[0]]

def generate_answer(question, contexts):
    context_text = "\n\n".join(
        [f"[æ–‡çŒ®{idx+1} æ¥è‡ªã€Š{c['meta']['book']}ã€‹ ç¬¬{c['meta']['page']}é¡µ]\n{c['text']}"
         for idx, c in enumerate(contexts)]
    )

    prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è¯å­¦çŸ¥è¯†åŠ©æ‰‹ï¼Œè¯·æ ¹æ®ä¸‹åˆ—èµ„æ–™å›žç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

{context_text}

é—®é¢˜ï¼š{question}
è¯·åŸºäºŽä¸Šè¿°èµ„æ–™ç®€æ´å›žç­”é—®é¢˜ï¼Œå¹¶åˆ—å‡ºå‚è€ƒå‡ºå¤„ï¼ˆä¹¦å+é¡µç ï¼‰ã€‚å¦‚èµ„æ–™ä¸è¶³ï¼Œè¯·æ˜Žç¡®è¯´æ˜Žã€‚
"""

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )
    return response.choices[0].message.content.strip()

# =====================
# ðŸš€ æ‰§è¡Œé—®ç­”
# =====================
if submit:
    with st.spinner("æ­£åœ¨æ£€ç´¢å¹¶ç”Ÿæˆç­”æ¡ˆ..."):
        top_contexts = search_faiss(query)
        answer = generate_answer(query, top_contexts)

        st.success("âœ… å›žç­”å®Œæˆï¼š")
        st.markdown(answer)

        with st.expander("ðŸ“š æŸ¥çœ‹å¼•ç”¨æ®µè½"):
            for i, item in enumerate(top_contexts):
                st.markdown(f"**æ–‡çŒ®{i+1} - ç¬¬{item['meta']['page']}é¡µ - {item['meta']['book']}**")
                st.markdown(f"> {item['text']}")
